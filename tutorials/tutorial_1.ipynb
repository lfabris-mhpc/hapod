{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import time\n",
    "import shutil\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import hapod as hp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total available memory is 15.56 GB\n",
      "but 1.00 GB will be made unavailable\n",
      "the largest matrix for SVD is (3600000, 124) using <class 'numpy.float64'>\n",
      "the hapod can use chunks of 62 columns\n"
     ]
    }
   ],
   "source": [
    "\n",
    "memory_avail_total = hp.get_memory_size()\n",
    "memory_forbidden = 2**30\n",
    "print(f\"total available memory is {memory_avail_total / 2**30:.2f} GB\")\n",
    "print(f\"but {memory_forbidden / 2**30:.2f} GB will be made unavailable\")\n",
    "\n",
    "dtype = np.float64\n",
    "n_rows = 3600000\n",
    "\n",
    "n_svd_max_cols = hp.get_max_svd_columns(n_rows, \n",
    "                                memory_limit=memory_avail_total - memory_forbidden)\n",
    "print(f\"the largest matrix for SVD is {n_rows, n_svd_max_cols} using {dtype}\")\n",
    "\n",
    "n_chunk_max_cols = n_svd_max_cols // 2\n",
    "print(f\"the hapod can use chunks of {n_chunk_max_cols} columns\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a snapshots matrix of size (3600000, 700) would use 18.78 GB of memory\n",
      "for a balanced, full, merge tree, will need 16 chunks with maximum size 62 >= 43.750\n"
     ]
    }
   ],
   "source": [
    "n_cols = 700\n",
    "snapshots_matrix_memory = hp.get_matrix_memory_footprint((n_rows, n_cols))\n",
    "print(f\"a snapshots matrix of size {n_rows, n_cols} would use {snapshots_matrix_memory/2**30:.2f} GB of memory\")\n",
    "\n",
    "n_chunks = hp.get_n_chunks_balanced(n_cols, n_chunk_max_cols=n_chunk_max_cols)\n",
    "print(f\"for a balanced, full, merge tree, will need {n_chunks} chunks with maximum size {n_chunk_max_cols} >= {n_cols / n_chunks:.3f} average\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "work_dir = \"/scratch/lfabris/hapod_test\"\n",
    "os.makedirs(work_dir, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "refresh_snapshots = False\n",
    "snapshots_dir = os.path.join(work_dir, \"snapshots\")\n",
    "print(f\"simulating a snapshot matrix with size {(n_rows, n_cols)} under {snapshots_dir}\")\n",
    "\n",
    "if not os.path.isdir(snapshots_dir) or refresh_snapshots:\n",
    "    print(f\"create snapshots under {snapshots_dir}\")\n",
    "    shutil.rmtree(snapshots_dir)\n",
    "    os.makedirs(snapshots_dir, exist_ok=True)\n",
    "\n",
    "    print(\n",
    "        f\"storing {snapshots_matrix_memory / 2**30:.3f} GB worth of snapshots\"\n",
    "    )\n",
    "\n",
    "    rng = np.random.default_rng()\n",
    "\n",
    "    elapsed_snapshots = -time.perf_counter()\n",
    "    snapshots_fnames = []\n",
    "    for i in range(n_cols):\n",
    "        snapshot_fname = os.path.join(snapshots_dir, f\"snapshot_{i:04d}.npy\")\n",
    "        np.save(snapshot_fname, rng.random((n_rows, 1)))\n",
    "\n",
    "        snapshots_fnames.append(snapshot_fname)\n",
    "    elapsed_snapshots += time.perf_counter()\n",
    "    print(f\"created {len(snapshots_fnames)} snapshot files in {elapsed_snapshots:.3f}\")\n",
    "else:\n",
    "    snapshots_fnames = list(glob.glob(os.path.join(snapshots_dir, \"*.npy\")))\n",
    "    print(f\"found {len(snapshots_fnames)} snapshot files in {snapshots_dir}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "refresh_chunks = False\n",
    "chunks_dir = os.path.join(work_dir, \"chunks\")\n",
    "print(f\"simulating chunks of maximum size {n_rows, n_chunk_max_cols} under {chunks_dir}\")\n",
    "\n",
    "if not os.path.isdir(chunks_dir) or refresh_chunks:\n",
    "    print(f\"create chunks under {chunks_dir}\")\n",
    "    shutil.rmtree(chunks_dir)\n",
    "    os.makedirs(chunks_dir, exist_ok=True)\n",
    "\n",
    "    elapsed_chunks = -time.perf_counter()\n",
    "    chunks_fnames = hp.make_chunks(\n",
    "        snapshots_fnames,\n",
    "        chunks_dir,\n",
    "        # n_chunk_max_cols=n_chunk_max_cols,\n",
    "        n_chunks=n_chunks,\n",
    "    )\n",
    "    elapsed_chunks += time.perf_counter()\n",
    "    print(f\"created {len(chunks_fnames)} column chunks files in {elapsed_chunks:.3f}\")\n",
    "else:\n",
    "    chunks_fnames = list(glob.glob(os.path.join(chunks_dir, \"*.npy\")))\n",
    "    print(f\"found {len(chunks_fnames)} column chunks files in {chunks_dir}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunks_fnames = chunks_fnames[:8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "hapod_tmp_dir = os.path.join(work_dir, \"tmp\")\n",
    "\n",
    "elapsed_hapod = -time.perf_counter()\n",
    "Uu, ss = hp.hapod(chunks_fnames,\n",
    "                rank_max=n_chunk_max_cols,\n",
    "                temp_work_dir=hapod_tmp_dir,\n",
    "                verbose=True)\n",
    "elapsed_hapod += time.perf_counter()\n",
    "\n",
    "print(f\"finished hapod in {elapsed_hapod:.3f}\")\n",
    "print(f\"    U.shape {Uu.shape}\")\n",
    "print(f\"    ss.shape {ss.shape}\")\n",
    "\n",
    "np.save(os.path.join(work_dir, \"U.npy\"), Uu)\n",
    "np.save(os.path.join(work_dir, \"s.npy\"), ss)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
